"use strict";(self.webpackChunkbaked_docs=self.webpackChunkbaked_docs||[]).push([[2838],{4351:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2024/05/31/2024-05-31-pipeline-test/pipeline-test","metadata":{"permalink":"/blog/2024/05/31/2024-05-31-pipeline-test/pipeline-test","source":"@site/blog/2024-05-31-pipeline-test/2024-05-31-pipeline-test.md","title":"Testing v0.7.0-bakedstudios.0.6.0b5","description":"Checklist","date":"2024-05-31T00:00:00.000Z","tags":[{"label":"nuke","permalink":"/blog/tags/nuke"},{"label":"pipeline","permalink":"/blog/tags/pipeline"},{"label":"flow","permalink":"/blog/tags/flow"},{"label":"nodes&layers","permalink":"/blog/tags/nodes-layers"}],"readingTime":1.29,"hasTruncateMarker":false,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Testing v0.7.0-bakedstudios.0.6.0b5","authors":["cameron"],"tags":["nuke","pipeline","flow","nodes&layers"]},"unlisted":false,"nextItem":{"title":"Update to render_template.nk","permalink":"/blog/2024/04/08/2024-04-08-new-render-template/new-render-template"}},"content":"## Checklist\\n\\n- [x] Flow Production Tracking loads Pipeline Toolkit and creates appropriate directories in Suite and on Basket.\\n\\n- [x] Nuke launches properly.\\n\\n- [x] Nuke project template is read from Suite.\\n\\n- [ ] Plate and ref versions for shotgrid are created properly from Basket.\\n\\n- [ ] Once assigned, shots are sorted based on storage location field in Flow and ingested. Refs are copied to their new locations. (ingest formats are working.)\\n\\n- [ ] No duplicate folders are created.\\n\\n- [ ] Published support files adhere to correct file paths dictated by storage location field in Flow.\\n\\n- [ ] OCIO config sets properly and v000s look correct - and save to appropriate locations in Suite and Basket.\\n\\n- [x] Workfiles app works correctly, and artists can open work.\\n\\n- [x] OCIO viewer in nuke works.\\n\\n- [x] Flow Production Tracking write node is free of bugs and includes metadata knob.\\n\\n- [ ] Send nuke to deadline works, and deadline is able to read from suite to grab data for render.\\n\\n- [ ] Read from write works and publisher correctly publishes.\\n\\n- [ ] Movie for Flow is rendered on Deadline. baked.render_artist_mov is findable.\\n\\n- [x] Color and slate look correct.\\n\\n- [ ] Statuses are set correctly on upload and tasks are correct.\\n\\n- [ ] LA side exports of Suite and Basket shots render on deadline correctly for client versions - outputting to 1_IO/3_DELIVERY/\\\\{playlist_name}\\n\\n- [ ] Files from Suite copy back to Basket without needing to replace existing data."},{"id":"/2024/04/08/2024-04-08-new-render-template/new-render-template","metadata":{"permalink":"/blog/2024/04/08/2024-04-08-new-render-template/new-render-template","source":"@site/blog/2024-04-08-new-render-template/2024-04-08-new-render-template.md","title":"Update to render_template.nk","description":"Changes have been made to the rendertemplate.nk file for the nuke transcoder.","date":"2024-04-08T00:00:00.000Z","tags":[{"label":"nuke","permalink":"/blog/tags/nuke"}],"readingTime":0.37,"hasTruncateMarker":false,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Update to render_template.nk","authors":["cameron"],"tags":["nuke"]},"unlisted":false,"prevItem":{"title":"Testing v0.7.0-bakedstudios.0.6.0b5","permalink":"/blog/2024/05/31/2024-05-31-pipeline-test/pipeline-test"},"nextItem":{"title":"Suite Studios \u2014 A SaaS Future for Baked Studios","permalink":"/blog/2024/03/15/2024-03-15-suite-saas-future/suite-saas-future"}},"content":">Changes have been made to the [render_template.nk](suite://files/Admin/resources/render_template/render_template.nk) file for the nuke transcoder.\\n\\n### Updates:\\n- Fewer copies/redundant nodes\\n- Categorized groups so you know where to look\\n- Movie write nodes set FPS with root.fps so always check project settings on this script.\\n- Slate reformats tobox with read_in.width so should cut down on slate size issues\\n- Relative file pathing with ../ allows for cross OS compatibility when loading the template from Suite."},{"id":"/2024/03/15/2024-03-15-suite-saas-future/suite-saas-future","metadata":{"permalink":"/blog/2024/03/15/2024-03-15-suite-saas-future/suite-saas-future","source":"@site/blog/2024-03-15-suite-saas-future/2024-03-15-suite-saas-future.mdx","title":"Suite Studios \u2014 A SaaS Future for Baked Studios","description":"This is an overview of how our pipeline could be improved by adopting Suite Studios cloud storage software.","date":"2024-03-15T00:00:00.000Z","tags":[{"label":"suite","permalink":"/blog/tags/suite"},{"label":"file-transfer","permalink":"/blog/tags/file-transfer"}],"readingTime":15.215,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Suite Studios \u2014 A SaaS Future for Baked Studios","authors":["cameron"],"tags":["suite","file-transfer"]},"unlisted":false,"prevItem":{"title":"Update to render_template.nk","permalink":"/blog/2024/04/08/2024-04-08-new-render-template/new-render-template"},"nextItem":{"title":"USDZ Cookie!","permalink":"/blog/2024/02/25/2024-02-25-usdz/usdz"}},"content":">This is an overview of how our pipeline could be improved by adopting Suite Studios cloud storage software.\\n\\n## **Introduction**\\nAt the core of every VFX pipeline is thoughtful consideration of the end user experience. At Baked, our users are artists, coordinators, supervisors and producers. A good pipeline needs the following qualities... \x3c!--truncate--\x3e\\n* Consistency \u2014 repeatable workflows and continuity in relation to application UX design, production management software integrations, render processes and workstation disk images.\\n* Security \u2014 follows best practices to the best of our knowledge - in this case, ideally MPA TPN assessed.\\n* Efficiency \u2014 there\u2019s no place for extensive manual copying and sorting. No one should have to sift through the filesystem.\\n* Performance \u2014 speedy, snappy, however you want to put it, the pipeline should have low latency and should present users with the broadest range of tools and resources available.\\n* Reliability \u2014 the pipeline cannot be glitchy, buggy or impede the working process in anyway.\\n\\nLet\u2019s start with the workstation. Ideally workstations have a shared image that gets copied from one environment to the next to provide a simple, consistent working experience for users.\\n\\n<img src={require(\'./workstations.png\').default} className=\\"invert-color\\" alt=\\"Workstations\\" style={{ width: \'40%\', height: \'auto\' }} />\\n\\nNow we need a pipeline. Baked has gone with ShotGrid\u2019s Pipeline Toolkit as the foundation for our pipeline. The user-friendly integrations with our primary production management software, as well as support for most digital content creation software, make this toolkit a huge help and an essential starting point. Using the toolkit, Baked and our partners can build things like ingest tools, export tools, environment specific tools, plugin managers and plenty other creative integrations that further our ability to meet the standards set for a good pipeline.\\n\\n<img src={require(\'./sgtk.png\').default} className=\\"invert-color\\" alt=\\"SGTK\\" style={{ width: \'50%\', height: \'auto\' }} />\\n\\nOne of the basic requirements of ShotGrid\u2019s Pipeline Toolkit is a storage location to work off of. The toolkit looks for a specified file path to read and write files based on the operating system, e.g Windows: `P:\\\\YOUR_DRIVE`, MAC: `/Volumes/YOUR_DRIVE`. These storage locations can be set on a per-project basis, but it\u2019s beneficial to keep things consistent by choosing one location to point to \u2014 enter BASKET.\\n\\n<img src={require(\'./bskt.png\').default} className=\\"invert-color\\" alt=\\"Basket\\" style={{ width: \'25%\', height: \'auto\' }} />\\n\\nBASKET is a shared network access storage and media management server on-premise in Baked\u2019s office in Los Angeles. It\u2019s an EVO model made by Studio Network Solutions. It does what it needs to do as a centralized location to read and write media files coming from workstations running digital content creation software.\\n\\n<img src={require(\'./cycle.png\').default} className=\\"invert-color\\" alt=\\"Cycle\\" style={{ width: \'75%\', height: \'auto\' }} />\\n\\n## \u26a0\ufe0f**The Problem**\\nBaked is a multi-location company with employees spread out across the country. BASKET is in Los Angles, not in the cloud, not in our offices in New York or Montana, not in our client\u2019s offices either (but we\u2019ll come back to that later). If I\u2019m working in New York, I can\u2019t specify BASKET as the toolkit storage location because I\u2019m not connected to BASKET there.\\n\\n### **Solution 1**\\nRemote Desktop \u2014 the first step in addressing the problem of getting people connected to BASKET from afar, is to move people closer to BASKET \u2014 duh! Remoting in using an application like Jump Desktop lets someone in New York, Montana or elsewhere connect to a workstation on-premise in Los Angeles that is a part of the network that includes BASKET.\\n\\n<img src={require(\'./remote.png\').default} className=\\"invert-color\\" alt=\\"Remote\\" />\\n\\nA quick comparison of Remote Desktop solutions:\\n|                      | Jump Desktop  | NICE DCV         | Parsec        |\\n|----------------------|:-------------:|:----------------:|:-------------:|\\n| Integration with AWS | \u274c             | \u2705                | \u274c             |\\n| Price                | 16/user/month | 13/desktop/month | 30/user/month |\\n| Good Performance     | \u2705             | \u2705                | \u274c             |\\n| Linux Support        | Sort of       | \u2705                | In Progress   |\\n\\nThis is a fast, efficient, and secure way of working. But what happens when we run out of workstations in Los Angeles? Or we have good reasons to want to work locally but in another location? Suppose we scale up somehow \u2014 whether another location, another server or adding something in the cloud\u2026 in doing so, how do we adhere to ShotGrid\u2019s storage location requirement?\\n\\n### **Solution 2**\\nSymlinks \u2014 Symlinks let us trick ShotGrid by replicating the specified storage location file path while actually pointing to another location on a local machine. So for example, while the shared storage available in New York might be `/Volumes/SNS/`, a symlink lets us make that storage also accessible locally from `/Volumes/BASKET/`. Great! But with multiple symlinks, and essentially multiple BASKETS around the country, we need to sync them so that assets saved to one \u201cBASKET\u201d can be accessed by ShotGrid toolkit from other locations.\\n\\n<img src={require(\'./symlink.png\').default} className=\\"invert-color\\" alt=\\"Symlink\\" style={{ width: \'75%\', height: \'auto\' }} />\\n\\n:::note\\nThe absolute UNC file path of the storage stays the same, but as far as ShotGrid is concerned, there\u2019s another \u201cBASKET\u201d in that location.\\n:::\\n\\n### **Solution 3**\\nSync Solutions \u2014 Resilio, Syncthing, and Signiant Jet are all sync solutions that scan for changes in one location and transfer files back and forth to keep multiple servers in sync. This part is pretty straightforward but there are a few things we need to consider: speed, reliability and sync-ability with the cloud. Let\u2019s look at Syncthing, it\u2019s supposed to be fast, it has transfer rules that make it quite reliable, but it doesn\u2019t sync with object storage in the cloud. However it is open source and free, so that\u2019s a great plus. Each sync solution comes with its pros and cons. For now let\u2019s use Syncthing, but we need a cloud workflow for when things get busy and we don\u2019t have enough hardware to support the resource demands \u2014 is there another way to \u2018sync\u2019 these servers?\\n\\n<img src={require(\'./sync_overview.png\').default} className=\\"invert-color\\" alt=\\"Sync Overview\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\n:::note\\nI\u2019ve added the FARM and AWS Thinkbox parts of our workflow in the above diagrams. These are important aspects of our workflow that we\u2019ll talk about in a moment.\\n:::\\n\\nHere\u2019s a brief comparison of different sync solutions:\\n|              | Speed | Price     | Cloud Compatible | As Fast as File System |\\n|-------------:|:-----:|:---------:|:----------------:|:----------------------:|\\n| Syncthing    | SLOW  | Free      | \u274c                | \u274c                      |\\n| Signiant Jet | FAST  | Expensive | \u2705                | \u274c                      |\\n| Resilio      | FAST  | Mid Range | \u2705                | \u274c                      |\\n\\n### **Solution 4**\\nLocally Accessible and Mountable Cloud Storage - maybe making a server the place you direct ShotGrid to in the first place is a mistake. Instead, one option to consider is a locally mounted cloud bucket. This cloud bucket would be the single source of truth that caches to local storage in these different geographic and cloud places. That\u2019s what Lucidlink and Suite do. Let\u2019s look at another diagram.\\n\\n<img src={require(\'./suite_overview.png\').default} className=\\"invert-color\\" alt=\\"Suite Overview\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\n:::note\\nNotice how the other two BSKTs are now called just by the make and model of the machine, we don\u2019t need symlinks anymore.\\n:::\\n\\nIn this diagram, you can see Suite plays a pretty heavy role. It\u2019s sitting in the middle because in this scenario, ShotGrid is directed to `Y:\\\\Suite` or `/Volumes/Suite/` as its primary storage location. The storage servers themselves: SNS, SNS and SYN are now for cacheing and slow storage. No more symlinks, or syncing needed. Suite also integrates with the cloud so that workflow is shown above as well.\\n\\nHere\u2019s a brief comparison of Suite and Lucidlink \u2014 just the dealbreakers:\\n\\n|                      | Suite           | Lucidlink       |\\n|----------------------|:---------------:|:---------------:|\\n| Price                | 75/TB + 10/user | 80/TB + 10/user |\\n| Responsive Team      | \u2705               | \u274c               |\\n| Easy install         | \u2705               | \u274c               |\\n| Proven Track Record  | \u274c               | \u2705               |\\n| Faster Speed         | \u2705               | \u274c               |\\n| Transactional Writes | \u2705               | \u274c               |\\n\\nAnd here\u2019s a brief comparison of Suite to a sync solution like Resilio:\\n|                | Suite                                | Resilio                     |\\n|----------------|--------------------------------------|-----------------------------|\\n| Technology     | FUSE, s3fs, proprietary acceleration | Bit Torrent                 |\\n| Method         | Cloud                                | P2P                         |\\n|                | Streaming/cacheing                   | Download/upload             |\\n| Metadata       | Independent                          | Bunched                     |\\n| Type           | File system                          | Application                 |\\n| Speed          | Instant, then stream                 | Wait, then work             |\\n| Price          | e.g 13k/year                         | 7k/year                     |\\n| Capacity       | e.g 15TB on Cloud                    | 500TB of monitored storage  |\\n| Max throughput | 10-24gbps (1gbps with our WiFi)      | 2gbps (1gbps with our WiFi) |\\n\\nThis cloud to local cacheing workflow can be powerful but there are some things we need to figure out.\\n\\n1. Most of the time, our core storage option is going to be barraged with read and write requests for large image sequences. If Suite is cloud storage, we need to make sure things get rendered locally first and then make their way to the cloud. It would be frustrating if render speeds were capped at our upload speeds.\\n\\n   - [x] Suite does indeed cache locally on render and so would not need to be slowed down to match upload speeds.\\n\\n2. Going off of that, we have a render farm. How do we configure Suite to be a target location for renders coming off the farm? Do we have to install Suite on every render node? Is that possible?\\n\\n   - [x] Suite can be configured to work with a render farm without needing to be installed on each individual node.\\n\\n3. Continuing off of that, does Suite work with cloud rendering?\\n\\n   - [x] The same workflow for on-premise render farms can be applied to cloud-based render farms.\\n\\n<img src={require(\'./suite_farm.png\').default} className=\\"invert-color\\" alt=\\"Suite Farm\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\nThere\u2019s a way to connect the dots here, and Suite solves what could have been a huge problem: internet speeds dictating render times and capacity rather than LAN ethernet cables. The cacheing goes both ways, down from and up to the cloud.\\n\\nIf there wasn\u2019t a way to do this, we\u2019d need another approach that allowed our NAS and LAN ecosystems to function properly, but also sync to other servers as well as cloud object storage. Signiant Jet and Resilio would come back to the table.\\n\\nO.K cool, so we\u2019ve solved a lot of issues by using Suite. What else needs to happen to build infrastructure for a solid pipeline?\\n\\n### **Solution 5**\\nFile Transfer \u2014 I said earlier that we\u2019d come back to the fact that BASKET isn\u2019t in our client offices. That\u2019s true, and this is where we need a file transfer solution to bring our data to our clients and theirs to us. Preferably a solution that uses a branded UI in the browser and a password protected link. Enter MASV, Media Shuttle, and Suite Connect.\\n\\nHere\u2019s a brief comparison of MASV, Suite Connect, and Signiant Media Shuttle.\\n|                     | Suite Connect | MASV      | Media Shuttle |\\n|---------------------|:-------------:|:---------:|:-------------:|\\n| Currently Available | \u274c             | \u2705         | \u2705             |\\n| Customizable UI     | \u2705             | \u2705         | \u2705             |\\n| API                 | Unknown       | \u2705         | \u2705             |\\n| REST API            | Unknown       | \u2705         | \u274c             |\\n| Price               | Free w/ Suite | 6k / year | 11k / year    |\\n| Growing Files       | Unknown       | \u2705         | \u274c             |\\n| On-prem Utilization | \u274c             | \u274c         | \u2705             |\\n| Send as Link        | \u2705             | \u2705         | \u274c             |\\n| Client Portal       | \u2705             | \u2705         | \u2705             |\\n\\nIt seems like we\u2019ll be going with MASV for now for file transfers \u2014 Suite\u2019s connect project is still in beta, but once it\u2019s available I see no reason not to switch considering it\u2019ll be free with our plan.\\n\\n<img src={require(\'./file_transfer.png\').default} className=\\"invert-color\\" alt=\\"File Transfer\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\nLet\u2019s look at some benefits of MASV while we\u2019re on the subject. MASV downloads from the cloud, so while there\u2019s an upload process on our end that might take a moment, from the client\u2019s perspective, things download extremely quickly. I\u2019m going to note here that Suite Connect will be the same.\\n\\nMASV has a great downloadable app that speeds up file transfers and allows for hot folders and automations. This app is a Media Shuttle killer in my opinion. MASV also has support for \u201cgrowing folders\u201d which basically means it uploads and sends files that are part of a larger render or stream that\u2019s still in progress. Think sending EXRs to another location while they\u2019re still rendering. We\u2019ll have to look more closely into use-cases but it\u2019s a powerful feature. I\u2019ll note again, that Suite has both features as well; a nice app and a way to stream/upload still-rendering files.\\n\\nMASV is a transfer solution that uploads your media to the cloud and makes it available for download elsewhere. Suite is exactly the same, but comes with a mountable storage solution we can work off of. MASV will work for us while Suite Connect is still in development, but long term, it\u2019s not really apples to apples.\\n\\n### **Solution 6**\\nMountable Storage for Supervisors and Producers \u2014 Aside from replacing a sync solution with cloud integration, and a file transfer solution, Suite has another important place in this pipeline. On the Supervisor and Producer side of things, Suite provides access to hi-res movie and EXR versions of shots that can be easily opened and reviewed via the ShotGrid interface. Anything in the pipeline will be viewable and editable remotely by coordinators, producers and supervisors.\\n\\n<img src={require(\'./supervisor.png\').default} className=\\"invert-color\\" alt=\\"Supervisor Workflow\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\n:::note\\nAddition of Remote Supervisors/Producers workflow.\\n:::\\n\\n<img src={require(\'./play_in_rv.png\').default} alt=\\"Play In RV\\" style={{ width: \'75%\', height: \'auto\' }} />\\n\\n:::note\\nMedia is directly loadable from the \u201cpath to frames\u201d and \u201cpath to movie\u201d fields that direct RV to EXRs and hi-res MOVs respectively. A user could do this on a train for example.\\n:::\\n\\n<img src={require(\'./rv_playback.png\').default} alt=\\"RV Playback\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\n> An example of RV playing back EXRs\\n\\n\\n## **\u26a0\ufe0fThe Other Problem**\\nDouble Paying for On-Premise and Cloud Storage \u2014 one of the issues with this set-up is that we have all this on-premise storage, why go after cloud storage too? Is there any reason to have both? Why bother if Syncthing is available?\\n\\n### **Response**\\nWe\u2019ll be paying the same for Suite with Suite Connect as we would for Syncthing and Media Shuttle. The only deal breaker in this whole thing is we can\u2019t afford anything other than Syncthing and MASV, in which case, fine that makes sense. Let\u2019s just align on the goal for when we have a more optimal cash flow situation.\\n\\nReasons why Suite is a better option than Syncthing & MASV or Syncthing & Media Shuttle:\\n1. One program, one single source of truth.\\n2. One support team\\n3. Price is comparable when counted together with Suite Connect (MS + Syncthing vs Suite/ MASV + Syncthing vs Suite)\\n4. We can understand it and won\u2019t need to consistent configuration and management by IT.\\n5. Reduced reliance on On-Prem - this is good incase of power outages, malfunctions etc\\n6. Access from anywhere with a login.\\n7. Encryption, transactional writes and redundancy.\\n8. Ease of use - it\u2019s super snappy.\\n9. Familiarity - it\u2019s just a mounted drive, we won\u2019t know the difference - it\u2019ll be just like basket but in the cloud too.\\n10. Without Suite, Coordinators, Producers and Supervisors will have to continue to dive into the file system and retrieve stuff by remoting in. This doesn\u2019t align with the criteria set up at the beginning of this document for what a good pipeline should be.\\n\\n## **\u26a0\ufe0fThe Other, Other Problem**\\nToo Much Media to Store on Cloud, will be Too Expensive \u2014 TRG was 30TB how on earth will we afford cloud storage for projects that size?\\n\\n### **Response**\\nTRG was 10TB in terms of what we\u2019d actually host on cloud, and that\u2019s without DWAB compression, but let\u2019s start there, with a 10TB per big project approach. If we have two Trigger Warnings going at the same time, we\u2019ll have other problems to worry about besides the cost of cloud storage. But let\u2019s say we\u2019re still worried about a 25 TB storage solution on the cloud. That will be about 22k without a discount from Suite. The point of cloud is that it\u2019s extremely flexible. We can scale up (on a month to month basis) from our 1 year commitment of 15TB to 25TB for the work, in which case we\u2019re working with a variable cost i.e money comes in goes up, money going out goes up. And then we can scale back down to 15TB \u2014 Money coming in goes down, money going out goes down. Currently we\u2019re operating on a fixed cost assumption \u2014 money coming in goes up, no change to money going out for infrastructure, money coming in goes down, still no change to money going out for infrastructure. Furthermore, if we have two TRGs happening simultaneously, we do not have the infrastructure on-prem to maintain that from a workstation standpoint. In order to have remote workstations on the cloud, we\u2019ll need that shared object storage. Working with Suite in that scenario is ideal. Shotgrid configs would not have to change. Syncthing cannot sync with object storage.\\n\\n## **Final Thoughts**\\nSuite and MASV are both excellent pieces of software. They\u2019re fast, reliable and can handle demanding image sequence based workflow. Between Suite Storage, MASV for now, and Suite Connect after development, we\u2019re going to have a lot of our bases covered. Our goals for this pipeline are consistency, security, efficiency, performance and reliability. Adopting a hybrid solution ensures performance and reliability on the on-premise side, while also enabling consistency through powerful syncing and shared file systems, as well as security with Suite\u2019s permissions functions. This approach ticks all the boxes, and the sooner we upgrade to this cloud native files system based, Shotgrid toolkit based, hybrid based Pipeline, the better off we\u2019ll be. Here\u2019s a before and after of our pipeline with these additions.\\n\\n### **Before**\\n<img src={require(\'./before.png\').default} className=\\"invert-color\\" alt=\\"Before\\" style={{ width: \'100%\', height: \'auto\' }} />\\n\\n### **After**\\n<img src={require(\'./after.png\').default} className=\\"invert-color\\" alt=\\"After\\" style={{ width: \'100%\', height: \'auto\' }} />"},{"id":"/2024/02/25/2024-02-25-usdz/usdz","metadata":{"permalink":"/blog/2024/02/25/2024-02-25-usdz/usdz","source":"@site/blog/2024-02-25-usdz/2024-02-25-usdz.md","title":"USDZ Cookie!","description":"Simple and fun way to access decades worth of techno dev from Apple and Pixar:","date":"2024-02-25T00:00:00.000Z","tags":[{"label":"usdz","permalink":"/blog/tags/usdz"}],"readingTime":0.33,"hasTruncateMarker":false,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"USDZ Cookie!","authors":["cameron"],"tags":["usdz"]},"unlisted":false,"prevItem":{"title":"Suite Studios \u2014 A SaaS Future for Baked Studios","permalink":"/blog/2024/03/15/2024-03-15-suite-saas-future/suite-saas-future"},"nextItem":{"title":"Deep Dive | Suite Studios","permalink":"/blog/2024/02/15/2024-02-15-suite/suite"}},"content":"Simple and fun way to access decades worth of techno dev from Apple and Pixar:\\n\\nExport a model or animation out of Maya with the USD plugin! Can drag and drop into Apple\u2019s \u201cReality Converter\u201d if you\u2019d like to tweak. And that\u2019s it, you should have a file that\u2019s openable in AR.\\n\\nHappy long weekend \ud83d\udc4d\ud83c\udffc\\n\\n<img src={require(\'./cookie_usdz.jpeg\').default} alt=\\"Cookie\\" style={{ width: \'50%\', height: \'auto\' }} />"},{"id":"/2024/02/15/2024-02-15-suite/suite","metadata":{"permalink":"/blog/2024/02/15/2024-02-15-suite/suite","source":"@site/blog/2024-02-15-suite/2024-02-15-suite.md","title":"Deep Dive | Suite Studios","description":"Suite Studios is a cloud storage solution that acts like a local drive, mounted to your computer. The company leverages FUSE, which stands for Filesystem in Userspace, and is a way to create a bridge between your computer\'s system and a variety of storage options or file systems without needing to deeply integrate them into the core part of your computer\'s operating system. With FUSE, you can add new types of storage systems or file formats to your computer easily, without needing to modify the core operating system.","date":"2024-02-15T00:00:00.000Z","tags":[{"label":"suite","permalink":"/blog/tags/suite"},{"label":"deep-dive","permalink":"/blog/tags/deep-dive"}],"readingTime":2.945,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Deep Dive | Suite Studios","authors":["cameron"],"tags":["suite","deep-dive"]},"unlisted":false,"prevItem":{"title":"USDZ Cookie!","permalink":"/blog/2024/02/25/2024-02-25-usdz/usdz"},"nextItem":{"title":"Deep Dive | Syncthing","permalink":"/blog/2024/01/30/2024-01-30-syncthing/syncthing"}},"content":"[Suite Studios](https://www.suitestudios.io/) is a cloud storage solution that acts like a local drive, mounted to your computer. The company leverages [FUSE](https://en.wikipedia.org/wiki/Filesystem_in_Userspace), which stands for Filesystem in Userspace, and is a way to create a bridge between your computer\'s system and a variety of storage options or file systems without needing to deeply integrate them into the core part of your computer\'s operating system. With FUSE, you can add new types of storage systems or file formats to your computer easily, without needing to modify the core operating system.\\n\\n\x3c!--truncate--\x3e\\n\\nThe company also leverages a whole lot of proprietary front end work as well as AWS s3 bucket storage to create a genuinely pleasant user experience with theoretically infinitely scalable storage.\\n\\nHere are some of the main ways Suite stands out:\\n\\n## Speedy and Direct Support\\nSuite has a built in support chat that connects you directly to the people running the company. There\'s no filter or redirect happening, you have a direct line at all times, and you\'ll always get a response, whether it\'s with an estimated response time, or the direct response from the person themselves.\\n\\n## Incredible User Interface and Ease of Use\\nSuite is really well designed. They have cool tricks like OS aware install instructions that you can access with a QR code, and a super intuitive permissions window. It\'s really snappy and pretty, and overall just feels like a premium piece of software.\\n\\n## The Storage Transfers are Insanely Fast\\nSince Suite isn\'t technically a sync solution, it\'s cloud storage, you\'re never sending files back and forth from a relay. You have a direct gateway to your cloud storage. It\'s like having a magical library on your bookshelf that includes all the books at the library, and makes one available to you when you want it. Rather than going to the library and borrowing a book, bringing it back. All the books just live in your bookshelf, ready to be accessed. [See here for How Cloud FUSE Storage Works](https://www.google.com/search?q=how+fuse+storage+works&oq=how+fuse+storage+works&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDIzNjJqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8#:~:text=Cloud%20Storage%20FUSE%20%7C%20Google,google.com%20%E2%80%BA%20...%20%E2%80%BA%20Documentation)\\n\\n## Transactional Writes\\nNo corrupted files. Basically a \\"transaction\\" in suite is a group of operations that are treated as a single all or nothing operation. When a transaction for a file write succeeds, there\'s 100% confidence that the file is correct and exists where it needs to. If a transaction fails, no updates to that file will be see by any user, client or future call referencing that file. This means that if any component in the Suite process fails, like your internet connection, the user can have confidence that the data that\'s in Suite, is 100% there, or 100% not there (with a clear warning that it wasn\'t added).\\n\\n## Versioning\\nSuite is set up so every instance of your storage is snapshotted and can be reverted back to based on the time and date you want to return to.\\n\\n## The Ability to Make your On-Premise Storage a Cloud Storage\\nSuite is basically an IT company that owns some really amazing proprietary UI stuff for accessing AWS cloud storage. Or maybe it\'s IBM... but it\'s built on a cloud platform, and exposed to users as a SUPER user friendly interface that makes the whole thing feel like magic. Part of that behind the scenes heavy lift can include turning your on-prem storage into cloud storage that Suite accesses instead of that IBM or AWS business, since cloud is essentially just someone else\'s storage system. A plan to incorporate Suite properly would essentially eliminate Media Shuttle, Syncthing and Google Drive in one go."},{"id":"/2024/01/30/2024-01-30-syncthing/syncthing","metadata":{"permalink":"/blog/2024/01/30/2024-01-30-syncthing/syncthing","source":"@site/blog/2024-01-30-syncthing/2024-01-30-syncthing.md","title":"Deep Dive | Syncthing","description":"tldr: Syncthing is a FOSS, decentralized file synchronization tool, facilitating seamless data synchronization across different locations. This article looks at Syncthing\'s underlying mechanisms and its application within media production companies, specifically highlighting its use here at Baked Studios to synchronize data across a Synology NAS in Montana, an SNS EVO storage system in Los Angeles, and another storage in New York. By diving into its architecture and operational framework, hopefully this will provide insights into Syncthing\'s utility in enhancing collaborative workflows and data management in the visual effects industry.","date":"2024-01-30T00:00:00.000Z","tags":[{"label":"syncthing","permalink":"/blog/tags/syncthing"},{"label":"deep-dive","permalink":"/blog/tags/deep-dive"}],"readingTime":2.97,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Deep Dive | Syncthing","authors":["cameron"],"tags":["syncthing","deep-dive"]},"unlisted":false,"prevItem":{"title":"Deep Dive | Suite Studios","permalink":"/blog/2024/02/15/2024-02-15-suite/suite"},"nextItem":{"title":"Tidbyt Status Monitor","permalink":"/blog/2024/01/25/2024-01-25-tidbyt/tidbyt"}},"content":"> tldr: [Syncthing](https://syncthing.net/) is a [FOSS](https://en.wikipedia.org/wiki/Free_and_open-source_software), decentralized file synchronization tool, facilitating seamless data synchronization across different locations. This article looks at Syncthing\'s underlying mechanisms and its application within media production companies, specifically highlighting its use here at Baked Studios to synchronize data across a Synology NAS in Montana, an SNS EVO storage system in Los Angeles, and another storage in New York. By diving into its architecture and operational framework, hopefully this will provide insights into Syncthing\'s utility in enhancing collaborative workflows and data management in the visual effects industry.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\nIn the fast-paced environment of media production, the ability to efficiently synchronize and manage data across multiple locations is often mentioned as important. Why? If you think about our entitre ShotGrid set-up it all relies on one thing: a shared storage for us all to work off of. Syncthing, an open-source peer-to-peer file synchronization tool, offers a robust solution by enabling devices to synchronize files directly with each other over a secure, encrypted connection. With some handy drive letter mapping, Syncthing gives us the coveted storage platform we need for ShotGrid to organize our company\'s workflow properly.\\n\\n## Architecture\\nAt its core, Syncthing utilizes a decentralized model, eschewing traditional client-server architectures for a peer-to-peer approach. This design facilitates direct data exchange between devices, ensuring efficiency and redundancy. Each device in the network operates both as a client and a server, contributing to the system\'s resilience and scalability. Syncthing incorporates Block Exchange Protocol (BEP) for efficient data transfer, employing a block-based synchronization mechanism that minimizes data transfer by only exchanging modified blocks within files. This means that while an initial sync can take a while, further syncs down the line are much faster because only changes are synced.\\n\\n## Security\\nSecurity in Syncthing is essential to stave off accusations of it being sketchy and open source, they employ TLS encryption to secure data transfers between devices. Additionally, each device is identified by a unique cryptographic certificate, enabling authenticated connections and preventing unauthorized access. The decentralized nature of Syncthing inherently reduces the risk of a single point of failure, enhancing the overall security posture of the synchronization network.\\n\\n## Efficiency and Reliability\\nSyncthing\'s configuration allows for real-time file synchronization, ensuring that changes made in one location are quickly reflected across all connected devices. This immediacy is crucial for media production environments and our shotgrid config where team members in different locations need access to the latest versions of files. Syncthing\'s network efficiency is further highlighted by its use of local networks when available, optimizing transfer speeds and reducing dependence on external internet connections. This means we can use syncthing to sync backup storage at a location as well.\\n\\n## Application here at Baked Studios\\nBaked Studios uses Syncthing to synchronize project data across our three key locations: a Synology NAS in Montana, an SNS EVO storage system in Los Angeles, and something in New York. Further deep dives into Syncthing and cloud storage are necessary if we want to use it there in future.\\n\\n## The Gist\\nSyncthing stands out as a highly effective solution for decentralized file synchronization, with significant advantages in terms of security, efficiency, and flexibility. Its application here at Baked Studios underscores the tool\'s potential to streamline collaborative workflows and data management in the demanding context of media production. As the visual effects industry continues to evolve, tools like Syncthing will play a crucial role in enabling seamless collaboration across the globe.\\n\\n### References:\\n\\n* Syncthing Documentation. https://docs.syncthing.net\\n* Block Exchange Protocol Specification. https://docs.syncthing.net/specs/bep-v1.html\\n\\n### Useful Video:\\n\\n* https://www.youtube.com/watch?v=PSx-BkMOPF4"},{"id":"/2024/01/25/2024-01-25-tidbyt/tidbyt","metadata":{"permalink":"/blog/2024/01/25/2024-01-25-tidbyt/tidbyt","source":"@site/blog/2024-01-25-tidbyt/2024-01-25-tidbyt.md","title":"Tidbyt Status Monitor","description":"Git repo//github.com/BakedStudios/baked-tools/tree/main/tidbyt-sg-monitor","date":"2024-01-25T00:00:00.000Z","tags":[{"label":"tidbyt","permalink":"/blog/tags/tidbyt"},{"label":"python","permalink":"/blog/tags/python"}],"readingTime":2.485,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Tidbyt Status Monitor","authors":["cameron"],"tags":["tidbyt","python"]},"unlisted":false,"prevItem":{"title":"Deep Dive | Syncthing","permalink":"/blog/2024/01/30/2024-01-30-syncthing/syncthing"},"nextItem":{"title":"Exploring \'knobChanged\'","permalink":"/blog/2024/01/15/2024-01-15-knob-changed/knob-changed"}},"content":">Git repo: https://github.com/BakedStudios/baked-tools/tree/main/tidbyt-sg-monitor\\n\\n>You need a Tidbyt for this to work! :robot:\\n\\nThe Tidbyt SG Monitor is a custom application designed to display data from ShotGrid (SG), specifically focusing on the count of Versions with a status of \\"cnv\\" within active projects. This documentation outlines how to set up and run the Tidbyt SG Monitor, including the necessary scripts and LaunchAgent configuration.\\n\\n\x3c!--truncate--\x3e\\n\\n## Overview\\n\\nThis solution involves three main components:\\n\\n1. **LaunchAgent Configuration**: A plist file to schedule and manage the execution of the SG_Data script.\\n2. **SG_Data Script**: A Python script that connects to ShotGrid, retrieves data, generates Starlark code for Tidbyt display, and commands to render and push the display content.\\n3. **Starlark Template**: A template used to dynamically generate Starlark code that defines what is displayed on the Tidbyt device, including fetching an SG icon and displaying the count of \\"cnv\\" statuses.\\n\\n## Setup Instructions\\n\\n### 1. LaunchAgent Configuration\\n\\n- **File Location**: `/Applications/tidbyt-sg-monitor/com.Tidbyt.SG_Data.plist`\\n- **Purpose**: Schedules the SG_Data script to run at a specified interval (every 30 seconds) and specifies output paths for standard output and errors.\\n\\n#### To Start the Agent:\\n\\n```shell\\nsudo launchctl bootstrap gui/$(id -u) /Applications/tidbyt-sg-monitor/com.Tidbyt.SG_Data.plist\\n```\\n\\n#### To Stop the Agent:\\n\\n```shell\\nlaunchctl bootout gui/$(id -u) /Applications/tidbyt-sg-monitor/com.Tidbyt.SG_Data.plist\\n```\\n\\n### 2. SG_Data Script\\n\\n- **Location**: `/Applications/tidbyt-sg-monitor/SG_Data.py`\\n- **Dependencies**: Requires `shotgun_api3` Python package.\\n- **Functionality**:\\n  - Connects to ShotGrid using provided credentials.\\n  - Queries for Versions with \\"cnv\\" status in active projects.\\n  - Generates a Starlark script for the Tidbyt display, embedding the count of found records.\\n  - Executes commands to render and push the content to a Tidbyt device.\\n\\n### 3. Starlark Template\\n\\nThe template dynamically generates a Starlark script, embedding the count of \\"cnv\\" statuses into a visual format suitable for Tidbyt devices. It fetches an SG icon and formats the display to show the data alongside the icon.\\n\\n## Execution Flow\\n\\n1. **Data Retrieval**: The SG_Data script connects to ShotGrid, retrieves the relevant data, and calculates the count of Versions with \\"cnv\\" status.\\n2. **Starlark Code Generation**: It then fills the Starlark template with this data, creating a script that defines the visual representation of the data on the Tidbyt device.\\n3. **Rendering and Display**: Lastly, the script uses `pixlet` commands to render the Starlark script into a format compatible with Tidbyt devices and pushes the rendered content to the device.\\n\\n## Additional Notes\\n\\n- Ensure that `pixlet` is installed and accessible from the command line.\\n- Replace `<YOUR TIDBYT TOKEN HERE>` with your actual Tidbyt API token in the final command within the SG_Data script.\\n- The paths and credentials used in the scripts should be adjusted according to your setup and security practices.\\n- The provided SG icon URL and other hardcoded values can be customized as needed.\\n\\nThis documentation aims to provide a clear understanding of how to configure and use the Tidbyt SG Monitor. For further customization or troubleshooting, refer to the documentation of the individual technologies involved (ShotGrid API, Tidbyt API, and LaunchAgents)."},{"id":"/2024/01/15/2024-01-15-knob-changed/knob-changed","metadata":{"permalink":"/blog/2024/01/15/2024-01-15-knob-changed/knob-changed","source":"@site/blog/2024-01-15-knob-changed/2024-01-15-knob-changed.md","title":"Exploring \'knobChanged\'","description":"A foray into the knobChanged function in Nuke.","date":"2024-01-15T00:00:00.000Z","tags":[{"label":"nuke","permalink":"/blog/tags/nuke"},{"label":"scripting","permalink":"/blog/tags/scripting"}],"readingTime":3.605,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Exploring \'knobChanged\'","authors":["cameron"],"tags":["nuke","scripting"]},"unlisted":false,"prevItem":{"title":"Tidbyt Status Monitor","permalink":"/blog/2024/01/25/2024-01-25-tidbyt/tidbyt"},"nextItem":{"title":"Release | v0.4.4-bakedstudios.0.4.1","permalink":"/blog/2023/12/31/2023-12-31-config-release-notes/config-release-notes"}},"content":"> A foray into the knobChanged function in Nuke.\\n\\n## Intro\\n\\nSo you\'re trying to update the value of one knob when the value of another changes. This functionality in Nuke is enabled by the knobChanged knobs that are hidden, but included, in most nodes. If you want to attach a script to a knobChanged knob, and also keep it when you save and reopen your Nuke script later, this guide\'s for you.\\n\\n\x3c!--truncate--\x3e\\n\\n## Part 1: KnobChanged\\n\\nNodes in Nuke obviously have a variety of controls, but some are visible and some not. One hidden control is known as \\"knobChanged.\\" Typically, this control starts empty, but you can attach a script or code to it. The attached code will execute whenever a designated knob\u2014or even all knobs\u2014undergo changes.\\n\\nHere\'s an example script you can attach to a `knobChanged` knob in your selected node:\\n```\\nsel = nuke.selectedNode()\\nsel.knob(\'knobChanged\').setValue(\'print(\\"Knob has changed!\\")\')\\n```\\n\\nWhere `sel = nuke.selectedNode()`: selects the currently active node in Nuke and stores it in the variable `sel` - and `sel.knob(\'knobChanged\').setValue(\'print(\\"Knob has been changed!\\")\')` accesses the \'knobChanged\' attribute of the selected node and sets its value to execute the print statement whenever a knob changes.\\n\\nThis is a simple set up, but it creates a lot of potential. Accessing the hidden knob allows the automation of triggers when all sorts of user interactions happen on the selected node.\\n\\nIf you get the idea, feel free to move on, if you want to read more about knobChanged:\\n\\nfurther reading:\\n- https://benmcewan.com/blog/2018/04/09/using-knobchanged-to-toggle-knob-states-on-gizmos/\\n- https://splitthediff.com/knob-changed\\n\\n## Part 2: Nuke Python Callbacks\\n\\n### What is a Callback?\\n\\nIn Python, a callback is essentially a function that you can pass as an argument to another function. This allows the code to be more dynamic and be executed when a specific event occurs. In Nuke, a callback is often used to trigger specific Python scripts when certain actions or events take place, like when a node is created or modified.\\n\\n### Why Use Callbacks in Nuke?\\n\\n1. **Workflow Automation**: You can automate repetitive tasks, like setting default values for nodes or auto-connecting nodes together.\\n2. **User Alerts**: You can set up alerts to notify you of certain changes or requirements, like warning you if a node\'s settings surpass a particular threshold.\\n3. **Quality Control**: Automate checks for naming conventions or specific settings that need to be maintained across a project.\\n\\n## Part 3: Built in Artist-Friendly Callback Knobs\\n\\nOne of the challenges in Nuke is assigning a script like the one above to a knob \'permanently\' so it stays with the script. Often, if you use the script editor, for example, to assign something to a knob, it\'ll only be included in that session. Unfortunately, Nuke scripts don\'t let you hardcode python directly into them, you have to either keep a .py script with your script or you have to find another way. Enter Nuke Python callback knobs.\\n\\nFor the intro gif, here\'s the script that makes that work, let\'s use it as an example.\\n```\\n# The function that you want added to the knob\\ndef kc_func():\\n    n = nuke.thisNode()\\n    k = nuke.thisKnob()\\n    if k.name() in ( \\"nameScheme_project\\", \'nameScheme_sequence\', \'nameScheme_shot\', \'nameScheme_task\', \'nameScheme_BKD\', \'nameScheme_version\'):\\n        new_value = nuke.tcl(\'value nameScheme_string\')\\n        n.knob(\'nameScheme_preview\').setValue(new_value)\\n        return f\\"Changed nameScheme_preview to {new_value}\\"\\n\\n# Find the node by name and set the knobChanged\\nnode = nuke.toNode(\\"BKD_Renderer1\\")\\nif node:\\n    node.knob(\'knobChanged\').setValue(\'kc_func()\')\\n```\\n\\nThis slighly more complex python script updates the knob `nameScheme_preview` when a set of other knobs on the node are updated. While this script essentially listens for any changes to those knobs, it still **needs to be run in the first place**, specifically the function in the script needs to be added to the knobChanged knob in the BKD_Renderer1 node. If the purpose is to avoid using a python button for example to trigger your changes, we\'ll want to have the python script run when the Nuke script is opened. This is made easy with the callback knob included in Project Settings / Python/ `nuke.addOnScriptLoad()`. This is a really user-friendly interface with a field where you can simply copy and paste the script you\'d like to have run on script load.\\n\\nSo that\'s kind of it for this example. It\'s small it scope, but can pack a punch if extrapolated to other circumstances.\\n\\nHere\'s more about the Artist friendly callback knobs in nuke:\\nhttps://www.youtube.com/watch?v=CBaU5ZvZlXI"},{"id":"/2023/12/31/2023-12-31-config-release-notes/config-release-notes","metadata":{"permalink":"/blog/2023/12/31/2023-12-31-config-release-notes/config-release-notes","source":"@site/blog/2023-12-31-config-release-notes/2023-12-31-config-release-notes.md","title":"Release | v0.4.4-bakedstudios.0.4.1","description":"Bug Fixes","date":"2023-12-31T00:00:00.000Z","tags":[{"label":"release","permalink":"/blog/tags/release"},{"label":"config","permalink":"/blog/tags/config"}],"readingTime":0.285,"hasTruncateMarker":false,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Release | v0.4.4-bakedstudios.0.4.1","authors":["cameron"],"tags":["release","config"]},"unlisted":false,"prevItem":{"title":"Exploring \'knobChanged\'","permalink":"/blog/2024/01/15/2024-01-15-knob-changed/knob-changed"},"nextItem":{"title":"Release | v0.4.1-bakedstudios.0.4.0","permalink":"/blog/2023/12/30/2023-12-30-config-release-notes/config-release-notes"}},"content":"### Bug Fixes\\n\\n* Mac support for Nuke Render submissions\\n* Non-breaking error in Nuke\u2019s log related to context_change on startup\\n* Publish for Assets from Maya\\n\\n### Updates\\n* Updated official Core, Engine, Frameworks and Apps to latest versions\\n* Updated Nodes&Layers ShotGrid Dropper app to version v0.1.0\\n* Updated Nodes&Layers Deliver app to latest version"},{"id":"/2023/12/30/2023-12-30-config-release-notes/config-release-notes","metadata":{"permalink":"/blog/2023/12/30/2023-12-30-config-release-notes/config-release-notes","source":"@site/blog/2023-12-30-config-release-notes/2023-12-30-config-release-notes.md","title":"Release | v0.4.1-bakedstudios.0.4.0","description":"This update should address the following issue/requests:","date":"2023-12-30T00:00:00.000Z","tags":[{"label":"release","permalink":"/blog/tags/release"},{"label":"config","permalink":"/blog/tags/config"}],"readingTime":0.32,"hasTruncateMarker":false,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Release | v0.4.1-bakedstudios.0.4.0","authors":["cameron"],"tags":["release","config"]},"unlisted":false,"prevItem":{"title":"Release | v0.4.4-bakedstudios.0.4.1","permalink":"/blog/2023/12/31/2023-12-31-config-release-notes/config-release-notes"},"nextItem":{"title":"Release | v0.4.0-bakedstudios.0.3.9","permalink":"/blog/2023/12/15/2023-12-15-config-release-notes/config-release-notes"}},"content":"This update should address the following issue/requests:\\n\\n\\n### Bug Fixes\\n* Restores the Deadline Submitter and Pipeline Tools menu\u2019s in Nuke\\n\\n### Deadline\\n* Adds a setting for Nuke renders to be submitted to Deadline with the \u201cnuke\u201d limitgroup applied.\\nThis limitgroup is already set in Baked\u2019s Deadline and only includes the D nodes.\\nThis limits the jobs to only render on these nodes."},{"id":"/2023/12/15/2023-12-15-config-release-notes/config-release-notes","metadata":{"permalink":"/blog/2023/12/15/2023-12-15-config-release-notes/config-release-notes","source":"@site/blog/2023-12-15-config-release-notes/2023-12-15-config-release-notes.md","title":"Release | v0.4.0-bakedstudios.0.3.9","description":"OCIO","date":"2023-12-15T00:00:00.000Z","tags":[{"label":"release","permalink":"/blog/tags/release"},{"label":"config","permalink":"/blog/tags/config"}],"readingTime":0.365,"hasTruncateMarker":false,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"title":"Release | v0.4.0-bakedstudios.0.3.9","authors":["cameron"],"tags":["release","config"]},"unlisted":false,"prevItem":{"title":"Release | v0.4.1-bakedstudios.0.4.0","permalink":"/blog/2023/12/30/2023-12-30-config-release-notes/config-release-notes"},"nextItem":{"title":"Deep Dive | TPN","permalink":"/blog/tpn-deep-dive"}},"content":"### OCIO\\n\\n* Autoload the ocio config if it exists in /global/configs/ocio/config.ocio\\n\\n### Loader\\n* Added loader support for this list of published files \u2013 Alembic Cache, Version Zero, Roto/Paint, REF\\n\\n### Platform Support\\n* MAC Support for Export tool\\n\\n### Global\\n\\n* Autoload NUKE_PATH in /global/configs/nuke\\n* Autoload PYTHONPATH in /global/configs/python\\n* Added config changes to support changing the default \u201c/global/configs\u201d folder structure\\n\\n### Plug-ins\\n\\n* Added support for tk-cpenv (CPENV Modules/Environments)"},{"id":"tpn-deep-dive","metadata":{"permalink":"/blog/tpn-deep-dive","source":"@site/blog/2023-09-29-tpn-deep-dive/2023-09-29-tpn-deep-dive.md","title":"Deep Dive | TPN","description":"TLDR: it\'s some security stuff. Mainly a way for big studios to keep their IP safe - for Baked, it could open the doors to more clients.","date":"2023-09-29T00:00:00.000Z","tags":[{"label":"TPN","permalink":"/blog/tags/tpn"},{"label":"deep-dive","permalink":"/blog/tags/deep-dive"}],"readingTime":2.705,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"slug":"tpn-deep-dive","title":"Deep Dive | TPN","authors":["cameron"],"tags":["TPN","deep-dive"]},"unlisted":false,"prevItem":{"title":"Release | v0.4.0-bakedstudios.0.3.9","permalink":"/blog/2023/12/15/2023-12-15-config-release-notes/config-release-notes"},"nextItem":{"title":"Deep Dive | Signiant Jet","permalink":"/blog/jet-deep-dive"}},"content":">TLDR: it\'s some security stuff. Mainly a way for big studios to keep their IP safe - for Baked, it could open the doors to more clients.\\n\\n## What is TPN?\\nTPN ([Trusted Partner Network](https://www.ttpn.org)) is wholly owned by the Motion Picture Association, essentially, they\'re committed to building and supporting a strong community network for keeping content safe. Mainly for the big six studios with big IP to safeguard.\\n\\n\x3c!--truncate--\x3e\\n\\nThe MPA Content Security Best Practices, maintained by the TPN, establish a **single** benchmark of minimum security preparedness. TPN Assessments measure a Service Provider\u2019s current security posture for site and application against the MPA Best Practices. Basically, among other things, it\'s a central assessment place so we don\'t have to worry about doing multiple assessments for each studio.\\n\\nThe TPN+ registry of global \u201cTrusted Partners\u201d provides a centralized source of truth for Content Owners to view and search for Service Providers by service type and TPN Blue or Gold Shield security status from which to make risk-based decisions effectively and independently. This is important, being on this roster is a big achievement and shows potential clients we\'re up to stuff on our security.\\n\\nEssentially, TPN is a network, app and assessment that we pay dues for to be on their roster. The roster shows our security status, TPN assessed or not. So the idea is you get an assessment and put our best foot forward so when someone comes looking for us, since they can see all our security measures, it benefits us to be the best prepared and well-set up we can be.\\n\\n## Where are we at?\\nOverall, we have a really robust and safe network at Baked Studios. We\'re currently in the process of completing a baseline evaluation, which will help. I\'ll update this article here with relevant and non-confidential information when we\'re done.\\n\\n## Where do we need to be?\\nHere are a few next steps once we baseline. Remember TPN is not mandatory, we\'d already be paying for our spot on the roster, it\'s more like a gold star that shows studios we play nice with their data - essentially bolstering the ROI for being on the roster in the first place.\\n\\n1. **Learn more about TPN Best Practices**: The MPA has created [content security best practices](https://www.ttpn.org/links-resources/) that we\'d need to familiarize ourselves with and implement.\\n\\n2. **Choose a Qualified TPN Assessor**: Only qualified [TPN Assessors](https://www.ttpn.org/assessors/#directory) can perform TPN assessments. These assessors have undergone training and testing to ensure they can effectively evaluate facilities and processes against industry security standards.\\n\\n3. **Do the Assessment**: This would be an in-depth look at our security infrastructure, both digital and physical, to ensure that it meets the standards set by the TPN.\\n\\n4. **Address Identified Issues**: If the TPN Assessor identifies any vulnerabilities or issues, we\'ll need to address these. We have a window to address and they\'ll update our status on the TPN+ network.\\n\\n5. **Annual Reassessment**: TPN assessments are good for one year, after which they need to be renewed.\\n\\nAnd that\'s it! It\'s kinda like the CARFAX of the the movie industry for big IP players. We just need to keep our \\"Car\\" up to date with it\'s latest inspections and security equivalents of oil changes..."},{"id":"jet-deep-dive","metadata":{"permalink":"/blog/jet-deep-dive","source":"@site/blog/2023-09-25-jet-deep-dive/2023-09-25-jet-deep-dive.md","title":"Deep Dive | Signiant Jet","description":"TLDR: Signiant Jet is a proposed software addition to our pipeline here at Baked. It syncs storage.","date":"2023-09-25T00:00:00.000Z","tags":[{"label":"deep-dive","permalink":"/blog/tags/deep-dive"},{"label":"file-transfer","permalink":"/blog/tags/file-transfer"}],"readingTime":1.53,"hasTruncateMarker":true,"authors":[{"name":"Cameron Target","title":"Pipeline Manager","url":"https://www.wearebaked.com/about","imageURL":"https://avatars.githubusercontent.com/u/127965975?s=400&u=9799eb0c2c2b7bcf45f47bb170c8a154fd4e7eb4&v=4","key":"cameron"}],"frontMatter":{"slug":"jet-deep-dive","title":"Deep Dive | Signiant Jet","authors":["cameron"],"tags":["deep-dive","file-transfer"]},"unlisted":false,"prevItem":{"title":"Deep Dive | TPN","permalink":"/blog/tpn-deep-dive"}},"content":">TLDR: Signiant Jet is a proposed software addition to our pipeline here at Baked. It syncs storage.\\n\\n## About Jet\\nOne of the most common use cases for Jet is when companies with multiple locations need to automate the movement or syncing of data between locations. Jet is most beneficial for recurring, time-critical transfers that involve large files moving over long distances. Think: syncing an asset library.\\n\\n\x3c!--truncate--\x3e\\n\\nThe installation of a single SDCX Server supports both Jet and Media Shuttle transfers. With this, companies can support workflows that involve person-initiated transfers, automated transfers or both, connecting to any storage, anywhere.\\n\\n## Manual Transfers\\nAlong with some other options, you can always trigger a sync/transfer manually. As well as use Media Shuttle to send files to and from users.\\n\\n## Hot folders\\nEasily set up hot folder jobs, where any files placed into a folder can trigger an automated transfer to one or more locations.\\n\\n## Scheduled Transfers\\nJobs can be set up to run at specific times of day or days of the week.\\n\\n## APIs\\nAlmost anything you can do from the Jet interface, you can also do programmatically via the APIs making it easy to extend Jets powers to add additional logic to jobs or connect Jet workflows to other systems. This means potential integrations with Slack and SG down the line etc...\\n\\nExtra credit: Jet supports simple hot folder, **manual** and scheduled workflows, and offers a modern, **event-driven API**, making it easy to integrate Jet with other applications. With event driven stuff, we can really refine our pipeline to transfer data based on statuses for example. Or when the publish button is clicked, telling Jet to transfer data at that specific time.\\n\\n>*Note:* Jet\'s API is mostly JavaScript and JSON files. Not my cup of tea, would need lots of external help."}]}}')}}]);